{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1NYRv94KEmxqxhu8YiXdR5jARzXWdr-lv","timestamp":1709346778501},{"file_id":"1i41l44tKS0O1SVW2k6aZ199w0-QyaLKi","timestamp":1707156273142}],"gpuType":"T4","collapsed_sections":["XRnOFwqk23W4","A5ovJE02CwKT","d7RMPSvMDL5U"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Notebook 2 AnaliseSentimentosBagOfWord - Alunos Regulares IA024-2024S1 FEEC-UNICAMP\n","\n","**Nome:** Caio Petrucci dos Santos Rosa\n","\n","**RA:** 248245"],"metadata":{"id":"9A4HuVIYGgXg"}},{"cell_type":"markdown","source":["## Instalação e importação de pacotes"],"metadata":{"id":"XRnOFwqk23W4"}},{"cell_type":"code","source":["!pip install torchtext\n","!pip install 'portalocker>=2.0.0'\n","!pip install Unidecode"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HA5BWLDCKmw3","executionInfo":{"status":"ok","timestamp":1709718782504,"user_tz":180,"elapsed":19269,"user":{"displayName":"Caio Petrucci Rosa","userId":"07502538663141318097"}},"outputId":"9fc46668-8672-42fa-d7fa-937ee6df45b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.31.0)\n","Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.1.0+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.25.2)\n","Requirement already satisfied: torchdata==0.7.0 in /usr/local/lib/python3.10/dist-packages (from torchtext) (0.7.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchtext) (2.1.0)\n","Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.0->torchtext) (2.0.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchtext) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchtext) (1.3.0)\n","Requirement already satisfied: portalocker>=2.0.0 in /usr/local/lib/python3.10/dist-packages (2.8.2)\n","Requirement already satisfied: Unidecode in /usr/local/lib/python3.10/dist-packages (1.3.8)\n"]}]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchtext.datasets import IMDB\n","from collections import Counter\n","import torch.nn as nn\n","import torch.optim as optim"],"metadata":{"id":"VorDvF62iyXF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## I - Vocabulário e Tokenização"],"metadata":{"id":"A5ovJE02CwKT"}},{"cell_type":"code","source":["import string\n","from unidecode import unidecode\n","\n","def normalize_string(s):\n","    return unidecode(s).strip(string.punctuation).lower()"],"metadata":{"id":"OXXN3JsO4zAP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# limit the vocabulary size to 20000 most frequent tokens\n","vocab_size = 20000\n","\n","counter = Counter()\n","for (target, line) in list(IMDB(split='train')):\n","    words = [ normalize_string(word) for word in line.split()]\n","    counter.update(words)\n","\n","# create a vocabulary of the 20000 most frequent tokens\n","most_frequent_words = sorted(counter, key=counter.get, reverse=True)[:vocab_size]\n","vocab = {word: i for i, word in enumerate(most_frequent_words, 1)}\n","vocab_size = len(vocab)"],"metadata":{"id":"u0J87ZCYs_Ta"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def encode_sentence(sentence, vocab):\n","    return [ vocab.get(normalize_string(word), 0) for word in sentence.split() ] # 0 for\n","\n","encode_sentence(\"I like Pizza.\", vocab)"],"metadata":{"id":"lz_t3mrTwOxL","executionInfo":{"status":"ok","timestamp":1709718793267,"user_tz":180,"elapsed":41,"user":{"displayName":"Caio Petrucci Rosa","userId":"07502538663141318097"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c92e1e19-04ec-4b96-f919-a16a341b7510"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[9, 38, 7893]"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["## II - Dataset"],"metadata":{"id":"5iV4bF8cDAj1"}},{"cell_type":"code","source":["from torch.nn.functional import one_hot\n","\n","# Dataset Class with One-hot Encoding\n","class IMDBDataset(Dataset):\n","    def __init__(self, split, vocab):\n","        self.raw_data = list(IMDB(split=split))\n","        self.vocab = vocab\n","        self.data = [ self.__encode_sample_to_onehot(sample) for sample in self.raw_data ]\n","\n","    def __encode_sample_to_onehot(self, sample):\n","        target, line = sample\n","        target = 1 if target == 1 else 0\n","        # one-hot encoding\n","        X = torch.zeros(len(self.vocab) + 1)\n","        for word in encode_sentence(line, self.vocab):\n","            X[word] = 1\n","        return X, torch.tensor(target)\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx]\n","\n","# Load Data with One-hot Encoding\n","train_data = IMDBDataset('train', vocab)\n","test_data = IMDBDataset('test', vocab)"],"metadata":{"id":"VDUyZoTPi262"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## III - Data Loader"],"metadata":{"id":"d7RMPSvMDL5U"}},{"cell_type":"code","source":["batch_size = 128\n","\n","# define dataloaders\n","train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","test_loader  = DataLoader(test_data,  batch_size=batch_size, shuffle=False)"],"metadata":{"id":"Y7tcZv2YDIog"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## IV - Modelo"],"metadata":{"id":"MwPeJ7h8DahT"}},{"cell_type":"code","source":["class OneHotMLP(nn.Module):\n","    def __init__(self, vocab_size):\n","        super(OneHotMLP, self).__init__()\n","\n","        self.fc1 = nn.Linear(vocab_size+1, 200)\n","        self.fc2 = nn.Linear(200, 1)\n","\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        o = self.fc1(x.float())\n","        o = self.relu(o)\n","        return self.fc2(o)\n","\n","# Model instantiation\n","model = OneHotMLP(vocab_size)"],"metadata":{"id":"6QuDhWvji7lt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## V - Laço de Treinamento - Otimização da função de Perda pelo Gradiente descendente"],"metadata":{"id":"iVAhdFGXDepU"}},{"cell_type":"code","source":["# Verifica se há uma GPU disponível e define o dispositivo para GPU se possível, caso contrário, usa a CPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","if device.type == 'cuda':\n","    print('GPU:', torch.cuda.get_device_name(torch.cuda.current_device()))\n","else:\n","    print('using CPU')"],"metadata":{"id":"RaH1Uv3yHih5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709718950127,"user_tz":180,"elapsed":3,"user":{"displayName":"Caio Petrucci Rosa","userId":"07502538663141318097"}},"outputId":"0d1035da-5e02-4fad-982c-6f8071169a02"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU: Tesla T4\n"]}]},{"cell_type":"code","source":["# Training loop with inital loss and perplexity during training\n","\n","import time\n","\n","model = model.to(device)\n","\n","# Define optimal learning rate\n","optimal_lr = 0.05\n","\n","# Define loss and optimizer\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.SGD(model.parameters(), lr=optimal_lr)\n","\n","# Evaluate loss before training\n","with torch.no_grad():\n","    initial_losses = []\n","    model.eval()\n","    for inputs, targets in train_loader:\n","        inputs = inputs.to(device)\n","        targets = targets.to(device)\n","        logits = model(inputs)\n","        initial_losses.append(criterion(logits.squeeze(), targets.float()))\n","    initial_loss = torch.tensor(initial_losses).mean()\n","    initial_PPL = torch.exp(initial_loss)\n","    print(f'Loss on training data before starting training:\\t{initial_loss:.4f}')\n","    print(f'Perplexity on training data before starting training:\\t{initial_loss:.4f}')\n","\n","# Training loop\n","num_epochs = 5\n","for epoch in range(num_epochs):\n","    start_time = time.time()  # Start time of the epoch\n","    model.train()\n","    for inputs, targets in train_loader:\n","        inputs = inputs.to(device)\n","        targets = targets.to(device)\n","        # Forward pass\n","        logits = model(inputs)\n","        loss = criterion(logits.squeeze(), targets.float())\n","        PPL = torch.exp(loss)\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    end_time = time.time()  # End time of the epoch\n","    epoch_duration = end_time - start_time  # Duration of epoch\n","\n","    print(f'Epoch [{epoch+1}/{num_epochs}], \\\n","            Loss: {loss.item():.4f}, \\\n","            Perplexity: {PPL.item():.4f}, \\\n","            Elapsed Time: {epoch_duration:.2f} sec')"],"metadata":{"id":"3P9sgKjfMgzu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709718958263,"user_tz":180,"elapsed":7081,"user":{"displayName":"Caio Petrucci Rosa","userId":"07502538663141318097"}},"outputId":"fa80b38e-ad6b-4876-cf84-0d5e10a4a676"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loss on training data before starting training:\t0.6935\n","Perplexity on training data before starting training:\t0.6935\n","Epoch [1/5],             Loss: 0.5013,             Perplexity: 1.6508,             Elapsed Time: 1.05 sec\n","Epoch [2/5],             Loss: 0.3896,             Perplexity: 1.4764,             Elapsed Time: 1.03 sec\n","Epoch [3/5],             Loss: 0.1991,             Perplexity: 1.2203,             Elapsed Time: 1.06 sec\n","Epoch [4/5],             Loss: 0.2558,             Perplexity: 1.2915,             Elapsed Time: 1.08 sec\n","Epoch [5/5],             Loss: 0.1913,             Perplexity: 1.2108,             Elapsed Time: 1.04 sec\n"]}]},{"cell_type":"markdown","source":["## VI - Avaliação"],"metadata":{"id":"Bwvahen5D1oM"}},{"cell_type":"code","source":["def bce_loss(y_prob, y_target):\n","    return - ( torch.mul( y_target, torch.log(y_prob) ) + torch.mul( (1-y_target), torch.log(1-y_prob) ) ).mean().item()"],"metadata":{"id":"Qz43V3aKKqP8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluation printing Accuracy, Loss and Perplexity\n","\n","model.eval()\n","\n","with torch.no_grad():\n","    losses = []\n","    correct = 0\n","    total = 0\n","    for inputs, targets in test_loader:\n","        inputs = inputs.to(device)\n","        targets = targets.to(device)\n","        logits = model(inputs)\n","        losses.append(bce_loss(torch.sigmoid(logits.squeeze(dim=1)), targets.float()))\n","        predicted = torch.round(torch.sigmoid(logits.squeeze(dim=1)))\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","    accuracy = 100 * correct/total\n","    loss = torch.tensor(losses).mean()\n","    PPL = torch.exp(loss)\n","\n","    print(f'Accuracy on test data:\\t{accuracy}%.')\n","    print(f'Loss on test data:\\t{loss}.')\n","    print(f'Perplexity on test data:\\t{PPL}.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709718964263,"user_tz":180,"elapsed":920,"user":{"displayName":"Caio Petrucci Rosa","userId":"07502538663141318097"}},"outputId":"740268d5-6ede-434b-dfec-881f35ed6399","id":"gTDH4UWp1CkL"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on test data:\t87.52%.\n","Loss on test data:\t0.30297234654426575.\n","Perplexity on test data:\t1.353877067565918.\n"]}]}]}